{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "RfXfYb8XVg6Y",
   "metadata": {
    "id": "RfXfYb8XVg6Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from sentence_transformers) (4.34.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from sentence_transformers) (0.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from sentence_transformers) (1.22.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from sentence_transformers) (1.3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from sentence_transformers) (1.11.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from sentence_transformers) (0.16.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from pinecone-client) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from pinecone-client) (6.0.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from pinecone-client) (0.7.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from pinecone-client) (4.7.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from pinecone-client) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from pinecone-client) (1.26.16)\n",
      "Requirement already satisfied: filelock in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2023.7.22)\n",
      "Requirement already satisfied: sympy in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: click in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from torchvision->sentence_transformers) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: neo4j in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (5.14.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages (from neo4j) (2022.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers pinecone-client\n",
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52f7baa4",
   "metadata": {
    "id": "52f7baa4"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import os, json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886433d1",
   "metadata": {
    "id": "886433d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhang\\.conda\\envs\\langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from tqdm import tqdm\n",
    "import requests, re\n",
    "import pinecone\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "GGfnex56EZqm",
   "metadata": {
    "id": "GGfnex56EZqm"
   },
   "outputs": [],
   "source": [
    "import neo4j\n",
    "from neo4j import GraphDatabase\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "NTx9IAy7EmUC",
   "metadata": {
    "id": "NTx9IAy7EmUC"
   },
   "outputs": [],
   "source": [
    "#triplet retrieval pipeline parameters\n",
    "\n",
    "url = \"neo4j+s://ef25c60e.databases.neo4j.io:7687\"\n",
    "username =\"username\"\n",
    "password = \"password\"\n",
    "\n",
    "graphDB_Driver = GraphDatabase.driver(url, auth=(username, password))\n",
    "\n",
    "# rel_str = 'ActTowards, CommunicatesWith, InteractsWith, Supplies, Demands, Acquires, Transforms, Decides, Assesses, Solves, Develops, Impacts, Manages, Moves, Happens'\n",
    "# node_str = 'Person, Company, Organization, Facility, Location, GeoPoliticalEntity, Time, Date, Event, Product, Regulation'\n",
    "\n",
    "rel_str = 'ActTowards, CommunicatesWith, InteractsWith, Supplies, Demands, Acquires, Transforms, Decides, Assesses, Solves, Develops, Impacts, Manages, Moves, Happens, Produce, is'\n",
    "node_str = 'Person, Company, Organization, Facility, Location, Country, GeoPoliticalEntity, Time, Date, Event, Product, Regulation, Journal, Paper, Number, Problem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Rg21c8SiEyLR",
   "metadata": {
    "id": "Rg21c8SiEyLR"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "#triplet retrieval\n",
    "def find_match_query(input_string):\n",
    "    pattern1 = re.compile(r'MATCH.*?\\n', re.DOTALL)\n",
    "    match1 = pattern1.search(input_string)\n",
    "    pattern2 = re.compile(r'MATCH.*?\\.', re.DOTALL)\n",
    "    match2 = pattern2.search(input_string)\n",
    "\n",
    "    if match1 and not match2:\n",
    "        return match1.group().rstrip().rstrip('.').rstrip(',')\n",
    "    elif match2 and not match1:\n",
    "        return match2.group().rstrip().rstrip('.').rstrip(',')\n",
    "    elif not match1 and not match2:\n",
    "        return None\n",
    "    elif len(match1.group()) < len(match2.group()):\n",
    "        return match1.group().rstrip().rstrip('.').rstrip(',')\n",
    "    else:\n",
    "        return match2.group().rstrip().rstrip('.').rstrip(',')\n",
    "\n",
    "\n",
    "# def find_match_query_ver2(input_string):\n",
    "#     pattern = re.compile(r'MATCH.*?[.\\n]', re.DOTALL)\n",
    "#     matches = pattern.findall(input_string)\n",
    "\n",
    "#     if not matches:\n",
    "#         return None\n",
    "\n",
    "#     chosen_match = min(matches, key=len)\n",
    "#     return chosen_match.rstrip().rstrip('.').rstrip(',')\n",
    "\n",
    "\n",
    "def output_triples(output_query, record_names):\n",
    "    pattern = r'\\((\\w+):(\\w+)\\)-\\[:(\\w+)\\]->\\((\\w+):(\\w+)\\)\\s*RETURN (\\w+)'\n",
    "    match = re.search(pattern, output_query)\n",
    "    if match:\n",
    "        s, stype, p, o, otype, var = match.groups()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    if var == s:\n",
    "        return [(n, p, o) for n in record_names]\n",
    "    elif var == o:\n",
    "        return [(s, p, n) for n in record_names]\n",
    "    elif var == p:\n",
    "        return [(s, n, o) for n in record_names]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "DLjHrIUmFIEM",
   "metadata": {
    "id": "DLjHrIUmFIEM"
   },
   "outputs": [],
   "source": [
    "def retrieve_triples(question, model, node=node_str, rel=rel_str, api_token= \"apitoken\", max_new_token=100):\n",
    "\n",
    "\n",
    "#     prompt = f'''Cypher is a query language designed for querying graph databases. It was initially developed by Neo4j, and is now an open standard for various graph databases.\n",
    "\n",
    "# There are pre-defined node labels in our Neo4j database, namely {node}. There are also 15 pre-defined relationship types, namely {rel}.\n",
    "\n",
    "# Here's an example of a Cypher query for a natural language query \"What companies are the suppliers of Louis Vuitton?\":\n",
    "\n",
    "# MATCH (company:Company)-[:Supplies]->(Louis_Vuitton:Company) RETURN company\n",
    "\n",
    "# This query retrieves companies from the class \"Company\" that are connected with Intel by a \"Supplies\" relationship, and then returns those companies. Never forget to return values in a query.\n",
    "\n",
    "# Using the node labels and the relationship types in the database, for the query in natural language \"{question},\" the corresponding Cypher query should be '''\n",
    "\n",
    "\n",
    "    prompt = f'''Cypher is a query language designed for querying graph databases. It was initially developed by Neo4j, and is now an open standard for various graph databases.\n",
    "\n",
    "There are pre-defined node labels in our Neo4j database, namely {node}. There are also 15 pre-defined relationship types, namely {rel}.\n",
    "\n",
    "Here's an example of a Cypher query for a natural language query \"What companies are the suppliers of Louis Vuitton?\":\n",
    "MATCH (company:Company)-[:Supplies]->(Louis_Vuitton:Company) RETURN company\n",
    "This query retrieves companies from the class \"Company\" that are connected with Intel by a \"Supplies\" relationship, and then returns those companies.\n",
    "\n",
    "Here's another example for query \"Who does China trade with?\":\n",
    "MATCH (China:Country)-[:InteractsWith]->(other_country:Country) RETURN other_country\n",
    "This query retrieves countries from the class \"Country\" that are connected with China by a \"InteractsWith\" relationship, as the predicate \"trade with\" closely aligns with the pre-defined relationship type \"InteractsWith\".\n",
    "\n",
    "Never forget to return values in a query. Using the node labels and the relationship types in the database, for the query in natural language \"{question},\" the corresponding Cypher query should be '''\n",
    "\n",
    "    client = InferenceClient(model=model, token=api_token)\n",
    "    output_text = client.text_generation(prompt, max_new_tokens=max_new_token)\n",
    "    try:\n",
    "        output_query = find_match_query(output_text) + '.name'\n",
    "    except:\n",
    "        output_query = \"\"\n",
    "    try:\n",
    "        db_records, summary, keys = graphDB_Driver.execute_query(output_query, database_=\"neo4j\")\n",
    "        record_names = [r[keys[0]] for r in db_records]\n",
    "    except:\n",
    "        record_names = []\n",
    "    output = output_triples(output_query, record_names)\n",
    "    output_str = []\n",
    "    if output is not None:\n",
    "        for triplet in output:\n",
    "            if type(triplet[0])==str and type(triplet[1])==str and type(triplet[2])==str: #correct output type\n",
    "                output_str.append(triplet)\n",
    "\n",
    "\n",
    "\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "zekiQ_zqCWtp",
   "metadata": {
    "id": "zekiQ_zqCWtp"
   },
   "outputs": [],
   "source": [
    "def read_file_and_process_sentences(file_path):\n",
    "    sentences = []\n",
    "    with open(file_path, 'r',encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "\n",
    "            cleaned_line = line.strip()\n",
    "            if cleaned_line:  # Check if the line is not empty after stripping\n",
    "                sentences.append(cleaned_line)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a01bb6",
   "metadata": {
    "id": "04a01bb6"
   },
   "outputs": [],
   "source": [
    "def sentence_embeddings(sentences, model='sentence-transformers/all-MiniLM-L6-v2'):\n",
    "    # generate embedding vectors for sentences.\n",
    "    # sentences: list of input sentences,\n",
    "    # model: sentence-transformers/all-MiniLM-L6-v2 as default\n",
    "    model = SentenceTransformer(model)\n",
    "    embeddings = model.encode(sentences,batch_size=128)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327d74a9",
   "metadata": {
    "id": "327d74a9"
   },
   "outputs": [],
   "source": [
    "def similarity_search(sentence_vectors, top_k=5, api_key=\"apikey\", environment=\"gcp-starter\", index=\"textsearch\"):\n",
    "    # return the top_k similar sentences for ench sentence_vector in inputs, inputs shape (n, )\n",
    "    # output list of shape (n, top_k)\n",
    "    pinecone.init(api_key=api_key,environment=environment)\n",
    "    index = pinecone.Index(\"textsearch\")\n",
    "    # print(index.describe_index_stats())\n",
    "\n",
    "    output_sentences=[]\n",
    "    for vector in sentence_vectors:\n",
    "        results = index.query(vector= vector.tolist(), top_k=top_k,include_metadata=True)\n",
    "        sentence=[]\n",
    "        for match_dict in results['matches']:\n",
    "            sentence.append(match_dict['metadata']['text'][1:-1]+\".\".strip())\n",
    "        output_sentences.append(sentence)\n",
    "    return output_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vo2XycrcUCk4",
   "metadata": {
    "id": "vo2XycrcUCk4"
   },
   "outputs": [],
   "source": [
    "# Some Back-up Prompts\n",
    "\n",
    "# prompt = f'''\n",
    "# RDF stands for Resource Description Framework, and it is a widely used format for representing information in the form of subject-predicate-object triplets in Knowledge Graph. Each RDF triplet consists of three components:\n",
    "\n",
    "# Subject: The subject is typically a resource or entity that you want to describe.\n",
    "# Predicate: The predicate, also known as the property or relationship, describes the relationship between the subject and the object.\n",
    "# Object: The object is the value or target of the statement.\n",
    "\n",
    "# Suppose you are an RDF triplet extraction model. I will give you 15 categories of predicates in the field of supply chain.\n",
    "\n",
    "# {category}\n",
    "\n",
    "# Give you some sentences, please extract all the RDF triplets based on the categories. Please form each triplet as (subject, predicate, object) + (predicate category) in the output. If no triplet is found, answer: None. Do not include other words in the answer.\n",
    "\n",
    "# Sentence: {sentence}\n",
    "\n",
    "# Triplets: '''\n",
    "\n",
    "\n",
    "# Prompt with no predicate types\n",
    "\n",
    "# prompt = f'''\n",
    "# In Knowledge Graphs, Resource Description Framework (RDF) serves as a widely adopted format for expressing information using subject-predicate-object triplets. Each RDF triplet consists of three primary components. The subject usually represents an entity. The predicate defines the connection between the subject and the object. The object is the value or target of the statement.\n",
    "\n",
    "# For instance, consider the sentence \"Apple contributes to the economy of China.\" In this case, the subject, predicate, and object are respectively \"Apple,\" \"contribute to,\" and \"the economy of China.\" We format the triplet output as (subject, predicate, object), which is (Apple, contribute to, the economy of China).\n",
    "\n",
    "# It's important to note that a single sentence can contain multiple triplets. For example, in the sentence, \"Walmart was trial-testing a service it developed with IBM to monitor produce,\" the output should consist of several triplets, including (Walmart, test, a service), (Walmart, develop with, IBM), and (Walmart, monitor, produce).\n",
    "\n",
    "# Given the above information, for the sentence \"{sentence},\" the correct output should be '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee199a01",
   "metadata": {
    "id": "ee199a01"
   },
   "outputs": [],
   "source": [
    "def triplet_extraction(sentences, start_idx, end_idx, category, model, api_token=\"apitoken\", max_new_token=100):\n",
    "\n",
    "    # extract triples of given setences, using giving model:\"meta-llama/Llama-2-70b-chat-hf\",\"meta-llama/Llama-2-70b-chat-hf\", \"bigscience/bloom-560m\",\"bigscience/bloom-3b\"\n",
    "    # input shape (n,1), output an excel with column：sentence_index\tsubject\tpredicate\tobject\tpredicate_type\n",
    "\n",
    "    client = InferenceClient(model=model, token=api_token)\n",
    "\n",
    "    pattern = r'\\(([^,]+), ([^,]+), ([^)]+)\\) \\+ \\(([^)]+)\\)'\n",
    "    # pattern = r'\\(([^,]+), ([^,]+), ([^)]+)\\)'\n",
    "\n",
    "    df = pd.DataFrame(columns = ['sentence_index', 'subject', 'predicate', 'object', 'predicate_type'])\n",
    "    # df = pd.DataFrame(columns = ['sentence_index', 'subject', 'predicate', 'object'])\n",
    "\n",
    "    sentence_idx = start_idx\n",
    "\n",
    "    for sentence in sentences[start_idx:end_idx]:\n",
    "\n",
    "        # Use a few-shot prompt\n",
    "        prompt = f'''\n",
    "In Knowledge Graphs, Resource Description Framework (RDF) serves as a widely adopted format for expressing information using subject-predicate-object triplets. Each RDF triplet consists of three primary components. The subject usually represents an entity. The predicate defines the connection between the subject and the object. The object is the value or target of the statement.\n",
    "\n",
    "In the field of supply chain, there are 15 pre-defined categories of predicates, which are as follows.\n",
    "\n",
    "{category}\n",
    "\n",
    "For instance, consider the sentence \"Apple contributes to the economy of China.\" In this case, the subject, predicate, and object are respectively \"Apple,\" \"contribute to,\" and \"the economy of China.\" The predicate \"contribute to\" belongs to the category of \"Impacts.\" Consequently, we format the triplet output as (subject, predicate, object) + (predicate category), which is (Apple, contribute to, the economy of China) + (Impacts) for this sentence.\n",
    "\n",
    "It's important to note that a single sentence can contain multiple triplets. For example, in the sentence, \"Walmart was trial-testing a service it developed with IBM to monitor produce,\" the output should consist of several triplets, including (Walmart, trial-test, a service) + (Assesses), (Walmart, develop with, IBM) + (Develops), (Walmart, monitor, production) + (Assesses).\n",
    "\n",
    "Given the above information, for the sentence \"{sentence},\" the correct output should be '''\n",
    "\n",
    "        output_text = client.text_generation(prompt, max_new_tokens=max_new_token)\n",
    "        # print(sentence)\n",
    "        # print(output_text)\n",
    "\n",
    "        matches = re.findall(pattern, output_text)\n",
    "        for m in matches:\n",
    "            phrase1, phrase2, phrase3, phrase4 = m\n",
    "            new_row = {'sentence_index': sentence_idx, 'subject': phrase1, 'predicate': phrase2, 'object': phrase3, 'predicate_type': phrase4}\n",
    "            df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "        sentence_idx += 1\n",
    "\n",
    "    return df\n",
    "    # df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16b6b015",
   "metadata": {
    "id": "16b6b015"
   },
   "outputs": [],
   "source": [
    "def chatbot_pipeline(questions, start_idx, end_idx, model, category, max_new_token=300, api_token=\"apitoken\"):\n",
    "\n",
    "    # generate answers for questions\n",
    "    # store triplets for questions and triplets,output answers in answers.txt\n",
    "    model_name=model.split(\"/\")[-1]\n",
    "    client = InferenceClient(model=model, token=api_token)\n",
    "    # triplet retrival\n",
    "    #If there are relevant triplets,keep the triplets,else keep the question for sentence similarity search\n",
    "\n",
    "    print(\"Triplet Retrieval\")\n",
    "\n",
    "    sentences_list=[]\n",
    "\n",
    "    for i in tqdm(range(start_idx, end_idx)):\n",
    "        triplet_list = retrieve_triples(question=questions[i], model=model)\n",
    "        \n",
    "        print(i,triplet_list)\n",
    "\n",
    "        if triplet_list is not None and len(triplet_list)!=0:\n",
    "            triplet_list_sentence = [\" \".join(triplet_list[i])+\".\" for i in range(0,len(triplet_list))] #list of sentences\n",
    "            sentences_list.append(triplet_list_sentence)\n",
    "        else:\n",
    "            sentences_list.append([questions[i]]) #None relevant triplets,keep the questions\n",
    "   # print(\"sentence_list:\",sentences_list)\n",
    "\n",
    "    print(\"Sentence Embedding and Similarity search\")\n",
    "    sentence_vectors=[]\n",
    "    background_sentences=[]\n",
    "    for i in tqdm(range(0,len(sentences_list))):\n",
    "        #print(sentences_list[i])\n",
    "        sentence_vector = sentence_embeddings(sentences_list[i])\n",
    "        #print(len(sentence_vector))\n",
    "        sentence_vectors.append(sentence_vector)\n",
    "        if len(sentence_vector)==1:\n",
    "\n",
    "            background_sentence = list(set(similarity_search(sentence_vector,top_k=5)[0])) #more sentences for questions\n",
    "\n",
    "        else:\n",
    "            background_sentence = list(set([sentence[0] for sentence in similarity_search(sentence_vector,top_k=1)]))\n",
    "            if len(background_sentence)>=20:\n",
    "                #chunk background sentence\n",
    "                background_sentence=background_sentence[0:20] \n",
    "                \n",
    "        background_sentences.append(background_sentence)\n",
    "        #print(\"back:\",background_sentences)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"back:\",background_sentences)\n",
    "    # join background sentences\n",
    "    background_sentences_join=[\"\" for i in range(0,len(background_sentences))]\n",
    "    answers=[]\n",
    "    for i in range(0, len(background_sentences)):\n",
    "          background_sentences_join[i]= (\"\\n\").join(background_sentences[i]) #join the relevant background information\n",
    "    #print(background_sentences)\n",
    "    \n",
    "    id=start_idx\n",
    "    with open(model_name+\"_\"+\"background_sentence.txt\", \"a\",encoding='utf-8') as file:\n",
    "        for sentence in background_sentences_join:\n",
    "            file.write(str(id)+\"<SEP>\"+'\\n')\n",
    "            file.write(sentence + '\\n')\n",
    "            id=id+1\n",
    "\n",
    "    print(\"Extracting triple from questions\")\n",
    "    df_questions = pd.DataFrame(columns = ['question_index','sentence_index', 'subject', 'predicate', 'object', 'predicate_type'])#might overflow\n",
    "    # df_questions = pd.DataFrame(columns = ['question_index','sentence_index', 'subject', 'predicate', 'object'])#might overflow\n",
    "    for i in tqdm(range(start_idx, end_idx)):\n",
    "        df = triplet_extraction(background_sentences[i-start_idx],start_idx=0, end_idx=len(background_sentences[i-start_idx]), category=category,model=model)\n",
    "        df['question_index'] = [i for j in range(0,len(df))]\n",
    "        df = df[['question_index', 'sentence_index', 'subject', 'predicate', 'object', 'predicate_type']]\n",
    "        # df = df[['question_index', 'sentence_index', 'subject', 'predicate', 'object']]\n",
    "        df_questions = pd.concat([df_questions,df], ignore_index=True)\n",
    "    df_questions = df_questions.drop('sentence_index', axis=1)\n",
    "    df_questions.to_csv(model_name+\"_\"+f'''questions_triples_{start_idx}_{end_idx}.csv''', index=False)\n",
    "\n",
    "    print(\"Generating answers\")\n",
    "    for i in tqdm(range(start_idx,end_idx)):\n",
    "        prompt = f'''\n",
    "        I will give you a question and related information. Please answer the question based on the given related information. Do not include other information.\n",
    "        Question: {questions[i]}\n",
    "        Related information:{background_sentences_join[i-start_idx]}\n",
    "\n",
    "        Answer:'''\n",
    "        output_text = client.text_generation(prompt,max_new_tokens=max_new_token)\n",
    "        # print(prompt)\n",
    "        # print(output_text)\n",
    "        answers.append(output_text.strip())\n",
    "    id=start_idx\n",
    "    with open(model_name+\"_\"+\"answers.txt\", \"a\",encoding='utf-8') as file:\n",
    "        for answer in answers:\n",
    "            file.write(str(id)+\"<SEP>\" '\\n')\n",
    "            file.write(answer + '\\n')\n",
    "            id=id+1\n",
    "\n",
    "    print(\"Extracting triple from answers\")\n",
    "    answer_sentences=[answers[i].split(\".\") for i in range(0,len(answers))]\n",
    "    df_answers = pd.DataFrame(columns = ['answer_index','sentence_index', 'subject', 'predicate', 'object', 'predicate_type']) # might overflow\n",
    "    # df_answers = pd.DataFrame(columns = ['answer_index','sentence_index', 'subject', 'predicate', 'object']) # might overflow\n",
    "    for i in tqdm(range(start_idx,end_idx)):\n",
    "\n",
    "        df=triplet_extraction(answer_sentences[i-start_idx],start_idx=0,end_idx=len(answer_sentences[i-start_idx]), category=category,model=model)\n",
    "        df['answer_index'] = [i for j in range(0,len(df))]\n",
    "        df = df[['answer_index','sentence_index', 'subject', 'predicate', 'object', 'predicate_type']]\n",
    "        # df = df[['answer_index','sentence_index', 'subject', 'predicate', 'object']]\n",
    "        df_answers=pd.concat([df_answers,df], ignore_index=True)\n",
    "    df_answers=df_answers.drop('sentence_index', axis=1)\n",
    "\n",
    "    df_answers.to_csv(model_name+\"_\"+f'''answers_triples_{start_idx}_{end_idx}.csv''', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9uSsgpzOVKU5",
   "metadata": {
    "id": "9uSsgpzOVKU5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6DNbY54BVKXN",
   "metadata": {
    "id": "6DNbY54BVKXN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3020e44",
   "metadata": {
    "id": "c3020e44"
   },
   "outputs": [],
   "source": [
    "category = '''Category 1: ActTowards\n",
    "Produce, create, present, implement, construct, operate, perform, conduct, run, tend, carry, start, build\n",
    "\n",
    "Category 2: CommunicatesWith\n",
    "describe, express, indicate, note, suggest, propose, discuss, explain, report, represent, illustrate, refer, mention, reveal, specify\n",
    "\n",
    "Category 3: InteractsWith\n",
    "connect, relate, associate, link, integrate, combine, incorporate, meet, interact, engage, cooperate, communicate, collaborate\n",
    "\n",
    "Category 4: Supplies\n",
    "give, share, offer, provide, supply, deliver\n",
    "\n",
    "Category 5: Demands\n",
    "need, require, demand, depend\n",
    "\n",
    "Category 6: Acquires\n",
    "order, obtain, purchase, buy, acquire, receive, trade, sell\n",
    "\n",
    "Category 7: Transforms\n",
    "change, transform, adapt, shift\n",
    "\n",
    "Category 8: Decides\n",
    "choose, decide, select, pick, opt\n",
    "\n",
    "Category 9: Assesses\n",
    "measure, assess, evaluate, calculate, test, examine, investigate\n",
    "\n",
    "Category 10: Solves\n",
    "solve, fix, resolve, address\n",
    "\n",
    "Category 11: Develops\n",
    "increase, develop, improve, grow, progress, advance, evolve, proceed\n",
    "\n",
    "Category 12: Impacts\n",
    "affect, influence, Impact, contribute, facilitate\n",
    "\n",
    "Category 13: Manages\n",
    "manage, control, coordinate, regulate, arrange, organize, sort\n",
    "\n",
    "Category 14: Moves\n",
    "move, go, travel, journey, walk\n",
    "\n",
    "Category 15: Happens\n",
    "occur, happen, continue, remain'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7faddd9b",
   "metadata": {
    "id": "7faddd9b"
   },
   "outputs": [],
   "source": [
    "def remove_parentheses(texts):\n",
    "    # Using regular expression to remove content within parentheses including the parentheses themselves\n",
    "    return [re.sub(r'\\([^)]*\\)', '', text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2468045",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "e2468045",
    "outputId": "642ba4bb-f25e-470c-b8ad-078e283aee24"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m triplet_extraction(\u001b[43moutput_sentences\u001b[49m[\u001b[38;5;241m1\u001b[39m], start_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, end_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, category\u001b[38;5;241m=\u001b[39mcategory, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-70b-chat-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "triplet_extraction(output_sentences[1], start_idx=0, end_idx=3, category=category, model=\"meta-llama/Llama-2-70b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca1fc7",
   "metadata": {
    "id": "5dca1fc7"
   },
   "outputs": [],
   "source": [
    "l = output_sentences\n",
    "for i in range(0, len(l)):\n",
    "    l[i] = (\"\\n\").join(l[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c33881",
   "metadata": {
    "id": "b3c33881"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875ac0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "6875ac0d",
    "outputId": "07e2dcd9-bcff-4bc7-970f-0f156b31bad8"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-b305427e7426>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    questions=read_file_and_process_sentences(\"questions.txt\"))\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "questions = [\"Introduce the supply chain of Walmart\", \"What are influences of blockchain in supply chain?\"]\n",
    "#questions=read_file_and_process_sentences(\"questions.txt\")\n",
    "model = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "chatbot_pipeline(questions, start_idx=0, end_idx=len(questions), model=model, category=category, max_new_token=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ffa878",
   "metadata": {
    "id": "38ffa878"
   },
   "outputs": [],
   "source": [
    "sentences = [' This study illustrates the various mechanisms by which blockchain help achieve the above supply chain objectives.  Some determinants of blockchain adoption in supply chain are the number and capabilities of related actors involved and the extent of pressure faced by the firms to stay competitive. These examples show the potential for economic, social, and environmental (sustainability) influences that can be managed in a blockchain-enabled supply chain. Researchers have begun to grapple with this nascent trend of block- chain deployment in various organizational objectives, but scholars have not systematically assessed the effects of blockchain on supply chain.  Blockchain impacts both supply chain process and product management, and financial transactions between different network parties (Hofmann, Strewe, and Bosia 2018).']\n",
    "df = triplet_extraction(sentences, 0, 1, category, model, api_token=\"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\", max_new_token=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f0fa0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "785f0fa0",
    "outputId": "254edefa-c87d-4805-8c66-ebb43f62760c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Retrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:08<00:00, 22.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Embedding and Similarity search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 1/3 [00:00<00:01,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back: [[]]\n",
      "['manufacturer Supplies Louis_Vuitton.', 'Company Supplies Louis_Vuitton.', 'DuPont Supplies Louis_Vuitton.']\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:04<00:02,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back: [[], [' Lariviere, \"Contracting to Assure Supply or What Did the Supplier Know and When Did He Know It?\", Working Paper, The Fuqua School of Business, Duke University, 1997a.', '  (5) The manufacturer produces the retailer orders.']]\n",
      "[]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back: [[], [' Lariviere, \"Contracting to Assure Supply or What Did the Supplier Know and When Did He Know It?\", Working Paper, The Fuqua School of Business, Duke University, 1997a.', '  (5) The manufacturer produces the retailer orders.'], []]\n",
      "Extracting triple from questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:25<00:00,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "chatbot_pipeline(questions, start_idx=0, end_idx=len(questions), model=\"bigscience/bloom-560m\", category=category, max_new_token=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_fwotnoFMSxr",
   "metadata": {
    "id": "_fwotnoFMSxr"
   },
   "outputs": [],
   "source": [
    "\n",
    "questions = ['What companies are the developers of Intel?','What are the properties of mulit product supply chain?', 'What are supply chain challenges when running a food business?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "daad8966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are the properties of mulit product supply chain?', 'What are supply chain challenges when running a food business?', 'What is green supply chain management?', 'What are some driving factors of green supply chain management in New York?', 'What is Deep Game Framework for supply chain analysis?', 'Can you give an example of a sustainable business model?', 'How does pandemic risk management differ from regular times in terms of supply chain?', 'What impacts did COVIS-19 have on global supply chain?', 'How could supply chain issues been avoided caused from COVID-19?', 'How has supply chain played a role in post COVID inflation']\n"
     ]
    }
   ],
   "source": [
    "questions=read_file_and_process_sentences(\"questions_final_100.txt\")\n",
    "\n",
    "print(questions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b31d9",
   "metadata": {
    "id": "de6b31d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Retrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                               | 2/50 [00:00<00:15,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n",
      "1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                            | 4/50 [00:00<00:08,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 []\n",
      "3 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 5/50 [00:01<00:07,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▌                                                                       | 7/50 [00:01<00:07,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 []\n",
      "6 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                     | 8/50 [00:01<00:06,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▍                                                                 | 10/50 [00:01<00:06,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 []\n",
      "9 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▋                                                              | 12/50 [00:02<00:06,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 []\n",
      "11 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▉                                                           | 14/50 [00:02<00:05,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 []\n",
      "13 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                         | 15/50 [00:02<00:06,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▉                                                      | 17/50 [00:03<00:06,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 []\n",
      "16 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▏                                                  | 19/50 [00:03<00:05,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 []\n",
      "18 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████▍                                               | 21/50 [00:03<00:05,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 []\n",
      "20 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▋                                            | 23/50 [00:04<00:04,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 []\n",
      "22 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 25/50 [00:04<00:03,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 []\n",
      "24 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████▎                                     | 27/50 [00:04<00:03,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 []\n",
      "26 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████████▌                                  | 29/50 [00:05<00:03,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 []\n",
      "28 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████▊                               | 31/50 [00:05<00:02,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 []\n",
      "30 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████████                            | 33/50 [00:05<00:02,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 []\n",
      "32 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████▍                        | 35/50 [00:05<00:02,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 []\n",
      "34 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████████████████████████████████████▋                     | 37/50 [00:06<00:01,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 []\n",
      "36 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████▉                  | 39/50 [00:06<00:01,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 []\n",
      "38 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 40/50 [00:06<00:01,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|███████████████████████████████████████████████████████████████████▏              | 41/50 [00:07<00:02,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████████████████████████████████████▉             | 42/50 [00:07<00:02,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|██████████████████████████████████████████████████████████████████████▌           | 43/50 [00:07<00:02,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 45/50 [00:08<00:01,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 []\n",
      "44 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████     | 47/50 [00:08<00:00,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 []\n",
      "46 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████▎ | 49/50 [00:08<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 []\n",
      "48 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 []\n",
      "Sentence Embedding and Similarity search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:53<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#model = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "model = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "\n",
    "chatbot_pipeline(questions, start_idx=0, end_idx=len(questions), model=model, category=category, max_new_token=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e9ccbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How much is the world population increasing by by 2050? ', 'The Dow Chemical Company manufactures how many product families? ', 'The Dow Chemical Company manufactures\\tat how many sites? ', 'The Dow Chemical Company manufactures in how many countries? ', 'What company serves 45000 customer locations daily? ', 'What was the $787 billion US Congress Bill passed in 2009? ', 'Spatial concentration of demand is measured by what? ', 'Green hydrogen can help decarbonize parts of what sector? ', 'What year did the Renewable Energy Sources Act begin? ', 'What government enacted the Renewable Energy Sources Act? ', 'What is one reason supply chain management seems to be struggling? ', 'What is the backbone of the global economy? ', 'What is a market relevant to supply chain where prices are determined by a spot market? ', 'US corn, soybeans, wheat and tobacco industries are what type of market? ', 'The war in which country has disrupted supply chains? ', 'The United States have been in trade disputes with what country? ', 'China has been in trade disputes with what country? ', 'UK households spend 10% income on what? ', 'How much of UK fruits and vegetables is self sufficient ', 'Covid-19 lock downs restricted what sector? ', 'What country had great economic recovery by lifting lockdowns when all other prefectures remained locked down? ', 'Company Information Database is collected by who? ', 'Company Linkage Database is collected by who? ', 'When did the Brazilian recession happen? ', 'What is the most central municipality in Brazil? ']\n"
     ]
    }
   ],
   "source": [
    "questions=read_file_and_process_sentences(\"questions_updated.txt\")\n",
    "questions=remove_parentheses(questions)\n",
    "print(questions[25:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78629907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Retrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                               | 1/25 [00:03<01:35,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▋                                                                            | 2/25 [00:07<01:20,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▉                                                                         | 3/25 [00:10<01:12,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                     | 4/25 [00:13<01:07,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 5/25 [00:16<01:06,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▉                                                               | 6/25 [00:20<01:04,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████▏                                                           | 7/25 [00:23<01:00,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▌                                                        | 8/25 [00:27<00:57,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▉                                                     | 9/25 [00:30<00:54,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 10/25 [00:34<00:51,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████                                              | 11/25 [00:37<00:48,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▎                                          | 12/25 [00:40<00:44,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▋                                       | 13/25 [00:44<00:41,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▉                                    | 14/25 [00:47<00:38,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 15/25 [00:50<00:32,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▍                             | 16/25 [00:54<00:29,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████████▊                          | 17/25 [00:57<00:25,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████████████████████████████████████████████████████████                       | 18/25 [01:00<00:22,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████▎                   | 19/25 [01:03<00:19,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 20/25 [01:07<00:16,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████████████████████████████████████▉             | 21/25 [01:10<00:13,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 22/25 [01:13<00:09,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▍      | 23/25 [01:16<00:06,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████████▋   | 24/25 [01:19<00:03,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [01:23<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 []\n",
      "Sentence Embedding and Similarity search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:29<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [04:28<00:00, 10.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:16<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:40<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "chatbot_pipeline(questions, start_idx=25, end_idx=len(questions), model=model, category=category, max_new_token=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b9692cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Walmart', 'Develops', 'Intel'), ('Company', 'Develops', 'Intel'), ('VCF', 'Develops', 'Intel'), ('suppliers', 'Develops', 'Intel'), ('Wilhelm', 'Develops', 'Intel'), ('Apple', 'Develops', 'Intel'), ('Apple', 'Develops', 'Intel'), ('SCN', 'Develops', 'Intel'), ('SCN', 'Develops', 'Intel'), ('IBM', 'Develops', 'Intel'), ('A', 'Develops', 'Intel'), ('Publ', 'Develops', 'Intel'), ('Amazon', 'Develops', 'Intel'), ('Company', 'Develops', 'Intel'), ('Company', 'Develops', 'Intel'), ('Company', 'Develops', 'Intel'), ('CSR', 'Develops', 'Intel'), ('supply_chain_management', 'Develops', 'Intel'), ('Ferrari', 'Develops', 'Intel'), ('Company', 'Develops', 'Intel'), ('SCRES', 'Develops', 'Intel'), ('Walmart', 'Develops', 'Intel'), ('Company', 'Develops', 'Intel'), ('Walmart', 'Develops', 'Intel'), ('developing', 'Develops', 'Intel'), ('Walmart', 'Develops', 'Intel'), ('Company', 'Develops', 'Intel'), ('CLSCs', 'Develops', 'Intel'), ('Maersk', 'Develops', 'Intel'), ('Walmart', 'Develops', 'Intel'), ('Digital', 'Develops', 'Intel'), ('Toyota', 'Develops', 'Intel'), ('retailer', 'Develops', 'Intel'), ('system', 'Develops', 'Intel'), ('manufacturer', 'Develops', 'Intel'), ('Walmart', 'Develops', 'Intel'), ('Company', 'Develops', 'Intel'), ('Company', 'Develops', 'Intel'), ('MEAP', 'Develops', 'Intel'), ('Ethereum', 'Develops', 'Intel'), ('Walmart', 'Develops', 'Intel'), ('GS1', 'Develops', 'Intel'), ('LUNAC', 'Develops', 'Intel')]\n"
     ]
    }
   ],
   "source": [
    " print(retrieve_triples(\"'What companies are the developers of Intel?'\", model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03611bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Walmart developed with what company?', 'Canada trades with what country?', 'iPhone is produced by what company?', 'Wilheim develops with what company?', 'IBM develops what type of technology?', 'Amazon develops with what company?', 'Where does Walmart produce goods?', 'Where does Walmart purchase produce?', 'Who does the US trade with?', 'What government produces PPE?', 'When was Stanford University established?', 'Europe develops with what country?', 'Europe impacts where?', 'Japan collaborated with who?', 'US collaborates with who?', 'Alibaba is produced where?', 'Apple develops with who?', 'Who invaded Iraq?', 'Omega develops with who?', 'McDonald develops with who?', 'Maersk partnered with who?', 'Bitcoin affects who?', 'Printers are imported from where?', 'Who does Lockheed Martin develop with?', 'Who does China trade with?']\n"
     ]
    }
   ],
   "source": [
    "questions = read_file_and_process_sentences(\"questions_triplet.txt\")\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20050523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walmart developed with what company?\n",
      "[('walmart', 'Develops', 'IBM'), ('walmart', 'Develops', 'Company'), ('walmart', 'Develops', 'measurement_instruments'), ('walmart', 'Develops', 'production_process'), ('walmart', 'Develops', 'IBM'), ('walmart', 'Develops', 'Walmart'), ('walmart', 'Develops', 'those'), ('walmart', 'Develops', 'network'), ('walmart', 'Develops', 'decisions'), ('walmart', 'Develops', 'Walmart'), ('walmart', 'Develops', 'B'), ('walmart', 'Develops', 'IBM'), ('walmart', 'Develops', 'Walmart'), ('walmart', 'Develops', 'Company'), ('walmart', 'Develops', 'Company'), ('walmart', 'Develops', 'Company'), ('walmart', 'Develops', 'evolve'), ('walmart', 'Develops', 'philosophy'), ('walmart', 'Develops', 'robotics'), ('walmart', 'Develops', 'Company'), ('walmart', 'Develops', 'dynamic_capability'), ('walmart', 'Develops', 'output'), ('walmart', 'Develops', 'Company'), ('walmart', 'Develops', 'performance'), ('walmart', 'Develops', 'SCP'), ('walmart', 'Develops', 'four_states'), ('walmart', 'Develops', 'Company'), ('walmart', 'Develops', 'increasingly_important'), ('walmart', 'Develops', 'IBM'), ('walmart', 'Develops', 'delivery_performance'), ('walmart', 'Develops', 'supply_chain'), ('walmart', 'Develops', 'the_final_product'), ('walmart', 'Develops', 'banker'), ('walmart', 'Develops', 'multiple_points_of_differentiation'), ('walmart', 'Develops', 'initial_demand_forecast'), ('walmart', 'Develops', 'verticalization'), ('walmart', 'Develops', 'Company'), ('walmart', 'Develops', 'SBB_double_auction'), ('walmart', 'Develops', 'development'), ('walmart', 'Develops', 'innovation'), ('walmart', 'Develops', 'downstream_capabilities'), ('walmart', 'Develops', 'IBM'), ('walmart', 'Develops', 'tpuna')]\n",
      "Canada trades with what country?\n",
      "[]\n",
      "iPhone is produced by what company?\n",
      "[]\n",
      "Wilheim develops with what company?\n",
      "[]\n",
      "IBM develops what type of technology?\n",
      "[('IBM', 'Develops', 'integrated_information_systems'), ('IBM', 'Develops', 'product_variety'), ('IBM', 'Develops', 'mobile_phones')]\n",
      "Amazon develops with what company?\n",
      "[('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'measurement_instruments'), ('Amazon', 'Develops', 'production_process'), ('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'Walmart'), ('Amazon', 'Develops', 'those'), ('Amazon', 'Develops', 'network'), ('Amazon', 'Develops', 'decisions'), ('Amazon', 'Develops', 'Walmart'), ('Amazon', 'Develops', 'B'), ('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'Walmart'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'evolve'), ('Amazon', 'Develops', 'philosophy'), ('Amazon', 'Develops', 'robotics'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'dynamic_capability'), ('Amazon', 'Develops', 'output'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'performance'), ('Amazon', 'Develops', 'SCP'), ('Amazon', 'Develops', 'four_states'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'increasingly_important'), ('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'delivery_performance'), ('Amazon', 'Develops', 'supply_chain'), ('Amazon', 'Develops', 'the_final_product'), ('Amazon', 'Develops', 'banker'), ('Amazon', 'Develops', 'multiple_points_of_differentiation'), ('Amazon', 'Develops', 'initial_demand_forecast'), ('Amazon', 'Develops', 'verticalization'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'SBB_double_auction'), ('Amazon', 'Develops', 'development'), ('Amazon', 'Develops', 'innovation'), ('Amazon', 'Develops', 'downstream_capabilities'), ('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'tpuna')]\n",
      "Where does Walmart produce goods?\n",
      "[]\n",
      "Where does Walmart purchase produce?\n",
      "[('walmart', 'Acquires', 'innovation_projects'), ('walmart', 'Acquires', 'mobile_phones'), ('walmart', 'Acquires', 'a_single_product'), ('walmart', 'Acquires', 'excess_inventory'), ('walmart', 'Acquires', 'forecast_update'), ('walmart', 'Acquires', 'produce_in_China'), ('walmart', 'Acquires', 'designs'), ('walmart', 'Acquires', 'OF'), ('walmart', 'Acquires', 'produce_in_China'), ('walmart', 'Acquires', 'SN'), ('walmart', 'Acquires', 'Transportation_Services'), ('walmart', 'Acquires', 'product'), ('walmart', 'Acquires', 'x'), ('walmart', 'Acquires', 'second_order'), ('walmart', 'Acquires', 'produce'), ('walmart', 'Acquires', 'social_media_information'), ('walmart', 'Acquires', 'm_inputs'), ('walmart', 'Acquires', 'supply_node')]\n",
      "Who does the US trade with?\n",
      "[]\n",
      "What government produces PPE?\n",
      "[]\n",
      "When was Stanford University established?\n",
      "[]\n",
      "Europe develops with what country?\n",
      "[]\n",
      "Europe impacts where?\n",
      "[]\n",
      "Japan collaborated with who?\n",
      "[]\n",
      "US collaborates with who?\n",
      "[]\n",
      "Alibaba is produced where?\n",
      "[]\n",
      "Apple develops with who?\n",
      "[]\n",
      "Who invaded Iraq?\n",
      "[]\n",
      "Omega develops with who?\n",
      "[]\n",
      "McDonald develops with who?\n",
      "[('mcdonald', 'Develops', 'IBM'), ('mcdonald', 'Develops', 'Company'), ('mcdonald', 'Develops', 'measurement_instruments'), ('mcdonald', 'Develops', 'production_process'), ('mcdonald', 'Develops', 'IBM'), ('mcdonald', 'Develops', 'Walmart'), ('mcdonald', 'Develops', 'those'), ('mcdonald', 'Develops', 'network'), ('mcdonald', 'Develops', 'decisions'), ('mcdonald', 'Develops', 'Walmart'), ('mcdonald', 'Develops', 'B'), ('mcdonald', 'Develops', 'IBM'), ('mcdonald', 'Develops', 'Walmart'), ('mcdonald', 'Develops', 'Company'), ('mcdonald', 'Develops', 'Company'), ('mcdonald', 'Develops', 'Company'), ('mcdonald', 'Develops', 'evolve'), ('mcdonald', 'Develops', 'philosophy'), ('mcdonald', 'Develops', 'robotics'), ('mcdonald', 'Develops', 'Company'), ('mcdonald', 'Develops', 'dynamic_capability'), ('mcdonald', 'Develops', 'output'), ('mcdonald', 'Develops', 'Company'), ('mcdonald', 'Develops', 'performance'), ('mcdonald', 'Develops', 'SCP'), ('mcdonald', 'Develops', 'four_states'), ('mcdonald', 'Develops', 'Company'), ('mcdonald', 'Develops', 'increasingly_important'), ('mcdonald', 'Develops', 'IBM'), ('mcdonald', 'Develops', 'delivery_performance'), ('mcdonald', 'Develops', 'supply_chain'), ('mcdonald', 'Develops', 'the_final_product'), ('mcdonald', 'Develops', 'banker'), ('mcdonald', 'Develops', 'multiple_points_of_differentiation'), ('mcdonald', 'Develops', 'initial_demand_forecast'), ('mcdonald', 'Develops', 'verticalization'), ('mcdonald', 'Develops', 'Company'), ('mcdonald', 'Develops', 'SBB_double_auction'), ('mcdonald', 'Develops', 'development'), ('mcdonald', 'Develops', 'innovation'), ('mcdonald', 'Develops', 'downstream_capabilities'), ('mcdonald', 'Develops', 'IBM'), ('mcdonald', 'Develops', 'tpuna')]\n",
      "Maersk partnered with who?\n",
      "[]\n",
      "Bitcoin affects who?\n",
      "[]\n",
      "Printers are imported from where?\n",
      "[('printer', 'Acquires', 'locally'), ('printer', 'Acquires', 'China')]\n",
      "Who does Lockheed Martin develop with?\n",
      "[('Lockheed_Martin', 'Develops', 'IBM'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'measurement_instruments'), ('Lockheed_Martin', 'Develops', 'production_process'), ('Lockheed_Martin', 'Develops', 'IBM'), ('Lockheed_Martin', 'Develops', 'Walmart'), ('Lockheed_Martin', 'Develops', 'those'), ('Lockheed_Martin', 'Develops', 'network'), ('Lockheed_Martin', 'Develops', 'decisions'), ('Lockheed_Martin', 'Develops', 'Walmart'), ('Lockheed_Martin', 'Develops', 'B'), ('Lockheed_Martin', 'Develops', 'IBM'), ('Lockheed_Martin', 'Develops', 'Walmart'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'evolve'), ('Lockheed_Martin', 'Develops', 'philosophy'), ('Lockheed_Martin', 'Develops', 'robotics'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'dynamic_capability'), ('Lockheed_Martin', 'Develops', 'output'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'performance'), ('Lockheed_Martin', 'Develops', 'SCP'), ('Lockheed_Martin', 'Develops', 'four_states'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'increasingly_important'), ('Lockheed_Martin', 'Develops', 'IBM'), ('Lockheed_Martin', 'Develops', 'delivery_performance'), ('Lockheed_Martin', 'Develops', 'supply_chain'), ('Lockheed_Martin', 'Develops', 'the_final_product'), ('Lockheed_Martin', 'Develops', 'banker'), ('Lockheed_Martin', 'Develops', 'multiple_points_of_differentiation'), ('Lockheed_Martin', 'Develops', 'initial_demand_forecast'), ('Lockheed_Martin', 'Develops', 'verticalization'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'SBB_double_auction'), ('Lockheed_Martin', 'Develops', 'development'), ('Lockheed_Martin', 'Develops', 'innovation'), ('Lockheed_Martin', 'Develops', 'downstream_capabilities'), ('Lockheed_Martin', 'Develops', 'IBM'), ('Lockheed_Martin', 'Develops', 'tpuna')]\n",
      "Who does China trade with?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "model = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "for question in questions:\n",
    "    print(question)\n",
    "    print(retrieve_triples(question, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec66509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walmart developed with what company?\n",
      "[('Walmart', 'Develops', 'Walmart'), ('Company', 'Develops', 'Walmart'), ('VCF', 'Develops', 'Walmart'), ('suppliers', 'Develops', 'Walmart'), ('Wilhelm', 'Develops', 'Walmart'), ('Apple', 'Develops', 'Walmart'), ('Apple', 'Develops', 'Walmart'), ('SCN', 'Develops', 'Walmart'), ('SCN', 'Develops', 'Walmart'), ('IBM', 'Develops', 'Walmart'), ('A', 'Develops', 'Walmart'), ('Publ', 'Develops', 'Walmart'), ('Amazon', 'Develops', 'Walmart'), ('Company', 'Develops', 'Walmart'), ('Company', 'Develops', 'Walmart'), ('Company', 'Develops', 'Walmart'), ('CSR', 'Develops', 'Walmart'), ('supply_chain_management', 'Develops', 'Walmart'), ('Ferrari', 'Develops', 'Walmart'), ('Company', 'Develops', 'Walmart'), ('SCRES', 'Develops', 'Walmart'), ('Walmart', 'Develops', 'Walmart'), ('Company', 'Develops', 'Walmart'), ('Walmart', 'Develops', 'Walmart'), ('developing', 'Develops', 'Walmart'), ('Walmart', 'Develops', 'Walmart'), ('Company', 'Develops', 'Walmart'), ('CLSCs', 'Develops', 'Walmart'), ('Maersk', 'Develops', 'Walmart'), ('Walmart', 'Develops', 'Walmart'), ('Digital', 'Develops', 'Walmart'), ('Toyota', 'Develops', 'Walmart'), ('retailer', 'Develops', 'Walmart'), ('system', 'Develops', 'Walmart'), ('manufacturer', 'Develops', 'Walmart'), ('Walmart', 'Develops', 'Walmart'), ('Company', 'Develops', 'Walmart'), ('Company', 'Develops', 'Walmart'), ('MEAP', 'Develops', 'Walmart'), ('Ethereum', 'Develops', 'Walmart'), ('Walmart', 'Develops', 'Walmart'), ('GS1', 'Develops', 'Walmart'), ('LUNAC', 'Develops', 'Walmart')]\n",
      "Canada trades with what country?\n",
      "[]\n",
      "iPhone is produced by what company?\n",
      "[]\n",
      "Wilheim develops with what company?\n",
      "[]\n",
      "IBM develops what type of technology?\n",
      "[]\n",
      "Amazon develops with what company?\n",
      "[('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'measurement_instruments'), ('Amazon', 'Develops', 'production_process'), ('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'Walmart'), ('Amazon', 'Develops', 'those'), ('Amazon', 'Develops', 'network'), ('Amazon', 'Develops', 'decisions'), ('Amazon', 'Develops', 'Walmart'), ('Amazon', 'Develops', 'B'), ('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'Walmart'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'evolve'), ('Amazon', 'Develops', 'philosophy'), ('Amazon', 'Develops', 'robotics'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'dynamic_capability'), ('Amazon', 'Develops', 'output'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'performance'), ('Amazon', 'Develops', 'SCP'), ('Amazon', 'Develops', 'four_states'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'increasingly_important'), ('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'delivery_performance'), ('Amazon', 'Develops', 'supply_chain'), ('Amazon', 'Develops', 'the_final_product'), ('Amazon', 'Develops', 'banker'), ('Amazon', 'Develops', 'multiple_points_of_differentiation'), ('Amazon', 'Develops', 'initial_demand_forecast'), ('Amazon', 'Develops', 'verticalization'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'SBB_double_auction'), ('Amazon', 'Develops', 'development'), ('Amazon', 'Develops', 'innovation'), ('Amazon', 'Develops', 'downstream_capabilities'), ('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'tpuna')]\n",
      "Where does Walmart produce goods?\n",
      "[]\n",
      "Where does Walmart purchase produce?\n",
      "[]\n",
      "Who does the US trade with?\n",
      "[]\n",
      "What government produces PPE?\n",
      "[]\n",
      "When was Stanford University established?\n",
      "[]\n",
      "Europe develops with what country?\n",
      "[]\n",
      "Europe impacts where?\n",
      "[]\n",
      "Japan collaborated with who?\n",
      "[]\n",
      "US collaborates with who?\n",
      "[]\n",
      "Alibaba is produced where?\n",
      "[]\n",
      "Apple develops with who?\n",
      "[]\n",
      "Who invaded Iraq?\n",
      "[]\n",
      "Omega develops with who?\n",
      "[]\n",
      "McDonald develops with who?\n",
      "[('McDonald', 'Develops', 'IBM'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'measurement_instruments'), ('McDonald', 'Develops', 'production_process'), ('McDonald', 'Develops', 'IBM'), ('McDonald', 'Develops', 'Walmart'), ('McDonald', 'Develops', 'those'), ('McDonald', 'Develops', 'network'), ('McDonald', 'Develops', 'decisions'), ('McDonald', 'Develops', 'Walmart'), ('McDonald', 'Develops', 'B'), ('McDonald', 'Develops', 'IBM'), ('McDonald', 'Develops', 'Walmart'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'evolve'), ('McDonald', 'Develops', 'philosophy'), ('McDonald', 'Develops', 'robotics'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'dynamic_capability'), ('McDonald', 'Develops', 'output'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'performance'), ('McDonald', 'Develops', 'SCP'), ('McDonald', 'Develops', 'four_states'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'increasingly_important'), ('McDonald', 'Develops', 'IBM'), ('McDonald', 'Develops', 'delivery_performance'), ('McDonald', 'Develops', 'supply_chain'), ('McDonald', 'Develops', 'the_final_product'), ('McDonald', 'Develops', 'banker'), ('McDonald', 'Develops', 'multiple_points_of_differentiation'), ('McDonald', 'Develops', 'initial_demand_forecast'), ('McDonald', 'Develops', 'verticalization'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'SBB_double_auction'), ('McDonald', 'Develops', 'development'), ('McDonald', 'Develops', 'innovation'), ('McDonald', 'Develops', 'downstream_capabilities'), ('McDonald', 'Develops', 'IBM'), ('McDonald', 'Develops', 'tpuna')]\n",
      "Maersk partnered with who?\n",
      "[]\n",
      "Bitcoin affects who?\n",
      "[]\n",
      "Printers are imported from where?\n",
      "[]\n",
      "Who does Lockheed Martin develop with?\n",
      "[]\n",
      "Who does China trade with?\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "for question in questions:\n",
    "    print(question)\n",
    "    print(retrieve_triples(question, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd643e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the second most central municipality in Brazil? ', 'Bioenergy Feedstock Library is developed and maintained by who? .', 'Bioenergy Feedstock Library is sponsored by who? ', 'Build to order supply chains have become commonplace in what industries? ', 'Dell has generated 160% return by invested capital by implementing what supply chain strategy? ', 'Canada’s Fair Rail for Grain Farmers Act acts on what two entities? .', 'Food quality and safety scandal in Europe? ', 'Food quality and safety scandal in US? ', 'Food quality and safety scandal in France? ', 'Food quality and safety scandal in Philippines? .']\n"
     ]
    }
   ],
   "source": [
    "questions=read_file_and_process_sentences(\"questions_final_100.txt\")\n",
    "questions=remove_parentheses(questions)\n",
    "print(questions[50:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f3d170e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Retrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                               | 1/25 [00:09<03:37,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▋                                                                            | 2/25 [00:16<03:11,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▉                                                                         | 3/25 [00:23<02:44,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                     | 4/25 [00:29<02:27,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 5/25 [00:35<02:08,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▉                                                               | 6/25 [00:41<02:02,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████▏                                                           | 7/25 [00:48<01:58,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▌                                                        | 8/25 [00:56<02:00,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▉                                                     | 9/25 [01:02<01:45,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 10/25 [01:08<01:37,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████                                              | 11/25 [01:16<01:38,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▎                                          | 12/25 [01:21<01:23,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▋                                       | 13/25 [01:27<01:16,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▉                                    | 14/25 [01:34<01:09,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 15/25 [01:40<01:04,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▍                             | 16/25 [01:47<00:57,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████████▊                          | 17/25 [01:53<00:51,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████████████████████████████████████████████████████████                       | 18/25 [02:00<00:45,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████▎                   | 19/25 [02:05<00:37,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 20/25 [02:11<00:30,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████████████████████████████████████▉             | 21/25 [02:18<00:25,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 22/25 [02:26<00:20,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▍      | 23/25 [02:32<00:12,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████████▋   | 24/25 [02:40<00:07,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [02:48<00:00,  6.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 []\n",
      "Sentence Embedding and Similarity search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:30<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [09:17<00:00, 22.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [02:15<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [05:37<00:00, 13.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Retrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                               | 1/25 [00:06<02:42,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▋                                                                            | 2/25 [00:12<02:27,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▉                                                                         | 3/25 [00:18<02:09,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                     | 4/25 [00:24<02:04,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 5/25 [00:31<02:11,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▉                                                               | 6/25 [00:36<01:52,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████▏                                                           | 7/25 [00:44<01:58,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▌                                                        | 8/25 [00:49<01:43,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▉                                                     | 9/25 [00:56<01:39,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 10/25 [01:03<01:38,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████                                              | 11/25 [01:12<01:43,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▎                                          | 12/25 [01:19<01:32,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▋                                       | 13/25 [01:24<01:18,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▉                                    | 14/25 [01:33<01:19,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 15/25 [01:40<01:12,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▍                             | 16/25 [01:48<01:07,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████████▊                          | 17/25 [01:55<00:58,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████████████████████████████████████████████████████████                       | 18/25 [02:01<00:47,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████▎                   | 19/25 [02:07<00:41,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 20/25 [02:13<00:32,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████████████████████████████████████▉             | 21/25 [02:20<00:25,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 22/25 [02:26<00:19,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▍      | 23/25 [02:33<00:13,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████████▋   | 24/25 [02:39<00:06,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [02:46<00:00,  6.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 []\n",
      "Sentence Embedding and Similarity search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:34<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [09:51<00:00, 23.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [01:43<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [02:36<00:00,  6.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Retrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                               | 1/25 [00:06<02:47,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▋                                                                            | 2/25 [00:13<02:30,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▉                                                                         | 3/25 [00:19<02:18,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                     | 4/25 [00:25<02:15,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 5/25 [00:31<02:05,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▉                                                               | 6/25 [00:38<01:59,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████▏                                                           | 7/25 [00:44<01:54,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▌                                                        | 8/25 [00:52<01:55,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▉                                                     | 9/25 [00:57<01:41,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 10/25 [01:03<01:31,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████                                              | 11/25 [01:10<01:28,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▎                                          | 12/25 [01:16<01:24,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▋                                       | 13/25 [01:21<01:12,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▉                                    | 14/25 [01:28<01:07,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 15/25 [01:35<01:04,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▍                             | 16/25 [01:41<00:58,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████████▊                          | 17/25 [01:46<00:47,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████████████████████████████████████████████████████████                       | 18/25 [01:52<00:41,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████▎                   | 19/25 [01:58<00:35,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 [('Garrett_Motion', 'Supplies', 'initial_forecast'), ('Garrett_Motion', 'Supplies', 'Company'), ('Garrett_Motion', 'Supplies', 'many_smaller_customers'), ('Garrett_Motion', 'Supplies', 'relationships'), ('Garrett_Motion', 'Supplies', 'retailer'), ('Garrett_Motion', 'Supplies', 'two_vendors'), ('Garrett_Motion', 'Supplies', 'Company')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 20/25 [02:04<00:30,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 [('Garrett_Motion', 'Supplies', 'initial_forecast'), ('Garrett_Motion', 'Supplies', 'Company'), ('Garrett_Motion', 'Supplies', 'many_smaller_customers'), ('Garrett_Motion', 'Supplies', 'relationships'), ('Garrett_Motion', 'Supplies', 'retailer'), ('Garrett_Motion', 'Supplies', 'two_vendors'), ('Garrett_Motion', 'Supplies', 'Company')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████████████████████████████████████▉             | 21/25 [02:10<00:24,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 22/25 [02:16<00:18,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▍      | 23/25 [02:20<00:10,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████████▋   | 24/25 [02:26<00:05,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [02:32<00:00,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 []\n",
      "Sentence Embedding and Similarity search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:30<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [09:18<00:00, 22.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [01:48<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [04:34<00:00, 10.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Retrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                               | 1/25 [00:06<02:46,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 [('Walmart', 'Develops', 'IBM'), ('Walmart', 'Develops', 'Company'), ('Walmart', 'Develops', 'measurement_instruments'), ('Walmart', 'Develops', 'production_process'), ('Walmart', 'Develops', 'IBM'), ('Walmart', 'Develops', 'Walmart'), ('Walmart', 'Develops', 'those'), ('Walmart', 'Develops', 'network'), ('Walmart', 'Develops', 'decisions'), ('Walmart', 'Develops', 'Walmart'), ('Walmart', 'Develops', 'B'), ('Walmart', 'Develops', 'IBM'), ('Walmart', 'Develops', 'Walmart'), ('Walmart', 'Develops', 'Company'), ('Walmart', 'Develops', 'Company'), ('Walmart', 'Develops', 'Company'), ('Walmart', 'Develops', 'evolve'), ('Walmart', 'Develops', 'philosophy'), ('Walmart', 'Develops', 'robotics'), ('Walmart', 'Develops', 'Company'), ('Walmart', 'Develops', 'dynamic_capability'), ('Walmart', 'Develops', 'output'), ('Walmart', 'Develops', 'Company'), ('Walmart', 'Develops', 'performance'), ('Walmart', 'Develops', 'SCP'), ('Walmart', 'Develops', 'four_states'), ('Walmart', 'Develops', 'Company'), ('Walmart', 'Develops', 'increasingly_important'), ('Walmart', 'Develops', 'IBM'), ('Walmart', 'Develops', 'delivery_performance'), ('Walmart', 'Develops', 'supply_chain'), ('Walmart', 'Develops', 'the_final_product'), ('Walmart', 'Develops', 'banker'), ('Walmart', 'Develops', 'multiple_points_of_differentiation'), ('Walmart', 'Develops', 'initial_demand_forecast'), ('Walmart', 'Develops', 'verticalization'), ('Walmart', 'Develops', 'Company'), ('Walmart', 'Develops', 'SBB_double_auction'), ('Walmart', 'Develops', 'development'), ('Walmart', 'Develops', 'innovation'), ('Walmart', 'Develops', 'downstream_capabilities'), ('Walmart', 'Develops', 'IBM'), ('Walmart', 'Develops', 'tpuna')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▋                                                                            | 2/25 [00:11<02:12,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 [('Canada', 'InteractsWith', 'States'), ('Canada', 'InteractsWith', 'China'), ('Canada', 'InteractsWith', 'China'), ('Canada', 'InteractsWith', 'Iraq')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▉                                                                         | 3/25 [00:17<02:01,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                     | 4/25 [00:21<01:45,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 5/25 [00:25<01:36,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 [('IBM', 'Develops', 'integrated_information_systems'), ('IBM', 'Develops', 'product_variety'), ('IBM', 'Develops', 'mobile_phones')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▉                                                               | 6/25 [00:31<01:37,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 [('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'measurement_instruments'), ('Amazon', 'Develops', 'production_process'), ('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'Walmart'), ('Amazon', 'Develops', 'those'), ('Amazon', 'Develops', 'network'), ('Amazon', 'Develops', 'decisions'), ('Amazon', 'Develops', 'Walmart'), ('Amazon', 'Develops', 'B'), ('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'Walmart'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'evolve'), ('Amazon', 'Develops', 'philosophy'), ('Amazon', 'Develops', 'robotics'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'dynamic_capability'), ('Amazon', 'Develops', 'output'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'performance'), ('Amazon', 'Develops', 'SCP'), ('Amazon', 'Develops', 'four_states'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'increasingly_important'), ('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'delivery_performance'), ('Amazon', 'Develops', 'supply_chain'), ('Amazon', 'Develops', 'the_final_product'), ('Amazon', 'Develops', 'banker'), ('Amazon', 'Develops', 'multiple_points_of_differentiation'), ('Amazon', 'Develops', 'initial_demand_forecast'), ('Amazon', 'Develops', 'verticalization'), ('Amazon', 'Develops', 'Company'), ('Amazon', 'Develops', 'SBB_double_auction'), ('Amazon', 'Develops', 'development'), ('Amazon', 'Develops', 'innovation'), ('Amazon', 'Develops', 'downstream_capabilities'), ('Amazon', 'Develops', 'IBM'), ('Amazon', 'Develops', 'tpuna')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████▏                                                           | 7/25 [00:35<01:27,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▌                                                        | 8/25 [00:41<01:27,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 [('Walmart', 'Acquires', 'innovation_projects'), ('Walmart', 'Acquires', 'mobile_phones'), ('Walmart', 'Acquires', 'a_single_product'), ('Walmart', 'Acquires', 'excess_inventory'), ('Walmart', 'Acquires', 'forecast_update'), ('Walmart', 'Acquires', 'produce_in_China'), ('Walmart', 'Acquires', 'designs'), ('Walmart', 'Acquires', 'OF'), ('Walmart', 'Acquires', 'produce_in_China'), ('Walmart', 'Acquires', 'SN'), ('Walmart', 'Acquires', 'Transportation_Services'), ('Walmart', 'Acquires', 'product'), ('Walmart', 'Acquires', 'x'), ('Walmart', 'Acquires', 'second_order'), ('Walmart', 'Acquires', 'produce'), ('Walmart', 'Acquires', 'social_media_information'), ('Walmart', 'Acquires', 'm_inputs'), ('Walmart', 'Acquires', 'supply_node')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▉                                                     | 9/25 [00:48<01:30,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 [('US', 'InteractsWith', 'States'), ('US', 'InteractsWith', 'China'), ('US', 'InteractsWith', 'China'), ('US', 'InteractsWith', 'Iraq')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 10/25 [00:54<01:26,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████                                              | 11/25 [01:00<01:23,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▎                                          | 12/25 [01:05<01:12,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▋                                       | 13/25 [01:12<01:10,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▉                                    | 14/25 [01:17<01:02,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 [('Japan', 'InteractsWith', 'States'), ('Japan', 'InteractsWith', 'China'), ('Japan', 'InteractsWith', 'China'), ('Japan', 'InteractsWith', 'Iraq')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 15/25 [01:22<00:55,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 [('US', 'InteractsWith', 'States'), ('US', 'InteractsWith', 'China'), ('US', 'InteractsWith', 'China'), ('US', 'InteractsWith', 'Iraq')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▍                             | 16/25 [01:26<00:44,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████████▊                          | 17/25 [01:30<00:38,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 [('Apple', 'Develops', 'IBM'), ('Apple', 'Develops', 'Company'), ('Apple', 'Develops', 'measurement_instruments'), ('Apple', 'Develops', 'production_process'), ('Apple', 'Develops', 'IBM'), ('Apple', 'Develops', 'Walmart'), ('Apple', 'Develops', 'those'), ('Apple', 'Develops', 'network'), ('Apple', 'Develops', 'decisions'), ('Apple', 'Develops', 'Walmart'), ('Apple', 'Develops', 'B'), ('Apple', 'Develops', 'IBM'), ('Apple', 'Develops', 'Walmart'), ('Apple', 'Develops', 'Company'), ('Apple', 'Develops', 'Company'), ('Apple', 'Develops', 'Company'), ('Apple', 'Develops', 'evolve'), ('Apple', 'Develops', 'philosophy'), ('Apple', 'Develops', 'robotics'), ('Apple', 'Develops', 'Company'), ('Apple', 'Develops', 'dynamic_capability'), ('Apple', 'Develops', 'output'), ('Apple', 'Develops', 'Company'), ('Apple', 'Develops', 'performance'), ('Apple', 'Develops', 'SCP'), ('Apple', 'Develops', 'four_states'), ('Apple', 'Develops', 'Company'), ('Apple', 'Develops', 'increasingly_important'), ('Apple', 'Develops', 'IBM'), ('Apple', 'Develops', 'delivery_performance'), ('Apple', 'Develops', 'supply_chain'), ('Apple', 'Develops', 'the_final_product'), ('Apple', 'Develops', 'banker'), ('Apple', 'Develops', 'multiple_points_of_differentiation'), ('Apple', 'Develops', 'initial_demand_forecast'), ('Apple', 'Develops', 'verticalization'), ('Apple', 'Develops', 'Company'), ('Apple', 'Develops', 'SBB_double_auction'), ('Apple', 'Develops', 'development'), ('Apple', 'Develops', 'innovation'), ('Apple', 'Develops', 'downstream_capabilities'), ('Apple', 'Develops', 'IBM'), ('Apple', 'Develops', 'tpuna')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████████████████████████████████████████████████████████                       | 18/25 [01:34<00:32,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████▎                   | 19/25 [01:40<00:29,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 [('Omega', 'Develops', 'IBM'), ('Omega', 'Develops', 'Company'), ('Omega', 'Develops', 'measurement_instruments'), ('Omega', 'Develops', 'production_process'), ('Omega', 'Develops', 'IBM'), ('Omega', 'Develops', 'Walmart'), ('Omega', 'Develops', 'those'), ('Omega', 'Develops', 'network'), ('Omega', 'Develops', 'decisions'), ('Omega', 'Develops', 'Walmart'), ('Omega', 'Develops', 'B'), ('Omega', 'Develops', 'IBM'), ('Omega', 'Develops', 'Walmart'), ('Omega', 'Develops', 'Company'), ('Omega', 'Develops', 'Company'), ('Omega', 'Develops', 'Company'), ('Omega', 'Develops', 'evolve'), ('Omega', 'Develops', 'philosophy'), ('Omega', 'Develops', 'robotics'), ('Omega', 'Develops', 'Company'), ('Omega', 'Develops', 'dynamic_capability'), ('Omega', 'Develops', 'output'), ('Omega', 'Develops', 'Company'), ('Omega', 'Develops', 'performance'), ('Omega', 'Develops', 'SCP'), ('Omega', 'Develops', 'four_states'), ('Omega', 'Develops', 'Company'), ('Omega', 'Develops', 'increasingly_important'), ('Omega', 'Develops', 'IBM'), ('Omega', 'Develops', 'delivery_performance'), ('Omega', 'Develops', 'supply_chain'), ('Omega', 'Develops', 'the_final_product'), ('Omega', 'Develops', 'banker'), ('Omega', 'Develops', 'multiple_points_of_differentiation'), ('Omega', 'Develops', 'initial_demand_forecast'), ('Omega', 'Develops', 'verticalization'), ('Omega', 'Develops', 'Company'), ('Omega', 'Develops', 'SBB_double_auction'), ('Omega', 'Develops', 'development'), ('Omega', 'Develops', 'innovation'), ('Omega', 'Develops', 'downstream_capabilities'), ('Omega', 'Develops', 'IBM'), ('Omega', 'Develops', 'tpuna')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 20/25 [01:45<00:24,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 [('McDonald', 'Develops', 'IBM'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'measurement_instruments'), ('McDonald', 'Develops', 'production_process'), ('McDonald', 'Develops', 'IBM'), ('McDonald', 'Develops', 'Walmart'), ('McDonald', 'Develops', 'those'), ('McDonald', 'Develops', 'network'), ('McDonald', 'Develops', 'decisions'), ('McDonald', 'Develops', 'Walmart'), ('McDonald', 'Develops', 'B'), ('McDonald', 'Develops', 'IBM'), ('McDonald', 'Develops', 'Walmart'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'evolve'), ('McDonald', 'Develops', 'philosophy'), ('McDonald', 'Develops', 'robotics'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'dynamic_capability'), ('McDonald', 'Develops', 'output'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'performance'), ('McDonald', 'Develops', 'SCP'), ('McDonald', 'Develops', 'four_states'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'increasingly_important'), ('McDonald', 'Develops', 'IBM'), ('McDonald', 'Develops', 'delivery_performance'), ('McDonald', 'Develops', 'supply_chain'), ('McDonald', 'Develops', 'the_final_product'), ('McDonald', 'Develops', 'banker'), ('McDonald', 'Develops', 'multiple_points_of_differentiation'), ('McDonald', 'Develops', 'initial_demand_forecast'), ('McDonald', 'Develops', 'verticalization'), ('McDonald', 'Develops', 'Company'), ('McDonald', 'Develops', 'SBB_double_auction'), ('McDonald', 'Develops', 'development'), ('McDonald', 'Develops', 'innovation'), ('McDonald', 'Develops', 'downstream_capabilities'), ('McDonald', 'Develops', 'IBM'), ('McDonald', 'Develops', 'tpuna')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████████████████████████████████████▉             | 21/25 [01:49<00:19,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 22/25 [01:54<00:13,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 [('Bitcoin', 'Impacts', 'temptation'), ('Bitcoin', 'Impacts', 'customers'), ('Bitcoin', 'Impacts', 'consumers'), ('Bitcoin', 'Impacts', 'Person'), ('Bitcoin', 'Impacts', 'them'), ('Bitcoin', 'Impacts', 'excitement_about_the_product'), ('Bitcoin', 'Impacts', 'us'), ('Bitcoin', 'Impacts', 'customer'), ('Bitcoin', 'Impacts', 'researchers')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▍      | 23/25 [02:00<00:10,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████████▋   | 24/25 [02:04<00:04,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 [('Lockheed_Martin', 'Develops', 'IBM'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'measurement_instruments'), ('Lockheed_Martin', 'Develops', 'production_process'), ('Lockheed_Martin', 'Develops', 'IBM'), ('Lockheed_Martin', 'Develops', 'Walmart'), ('Lockheed_Martin', 'Develops', 'those'), ('Lockheed_Martin', 'Develops', 'network'), ('Lockheed_Martin', 'Develops', 'decisions'), ('Lockheed_Martin', 'Develops', 'Walmart'), ('Lockheed_Martin', 'Develops', 'B'), ('Lockheed_Martin', 'Develops', 'IBM'), ('Lockheed_Martin', 'Develops', 'Walmart'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'evolve'), ('Lockheed_Martin', 'Develops', 'philosophy'), ('Lockheed_Martin', 'Develops', 'robotics'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'dynamic_capability'), ('Lockheed_Martin', 'Develops', 'output'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'performance'), ('Lockheed_Martin', 'Develops', 'SCP'), ('Lockheed_Martin', 'Develops', 'four_states'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'increasingly_important'), ('Lockheed_Martin', 'Develops', 'IBM'), ('Lockheed_Martin', 'Develops', 'delivery_performance'), ('Lockheed_Martin', 'Develops', 'supply_chain'), ('Lockheed_Martin', 'Develops', 'the_final_product'), ('Lockheed_Martin', 'Develops', 'banker'), ('Lockheed_Martin', 'Develops', 'multiple_points_of_differentiation'), ('Lockheed_Martin', 'Develops', 'initial_demand_forecast'), ('Lockheed_Martin', 'Develops', 'verticalization'), ('Lockheed_Martin', 'Develops', 'Company'), ('Lockheed_Martin', 'Develops', 'SBB_double_auction'), ('Lockheed_Martin', 'Develops', 'development'), ('Lockheed_Martin', 'Develops', 'innovation'), ('Lockheed_Martin', 'Develops', 'downstream_capabilities'), ('Lockheed_Martin', 'Develops', 'IBM'), ('Lockheed_Martin', 'Develops', 'tpuna')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [02:08<00:00,  5.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 [('China', 'InteractsWith', 'States'), ('China', 'InteractsWith', 'China'), ('China', 'InteractsWith', 'China'), ('China', 'InteractsWith', 'Iraq')]\n",
      "Sentence Embedding and Similarity search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [13:27<00:00, 32.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [01:36<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [03:19<00:00,  7.99s/it]\n"
     ]
    }
   ],
   "source": [
    "model = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "for i in range(0,4):\n",
    "    chatbot_pipeline(questions, start_idx=i*25, end_idx=(i+1)*25, model=model, category=category, max_new_token=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8af79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Retrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                               | 1/25 [00:00<00:04,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▋                                                                            | 2/25 [00:00<00:03,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▉                                                                         | 3/25 [00:00<00:03,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                     | 4/25 [00:00<00:03,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 5/25 [00:00<00:03,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▉                                                               | 6/25 [00:00<00:02,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████▏                                                           | 7/25 [00:01<00:02,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▌                                                        | 8/25 [00:01<00:02,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 []\n",
      "8 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████                                              | 11/25 [00:01<00:02,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 []\n",
      "10 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████▋                                       | 13/25 [00:01<00:01,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 [('time', 'Happens', 'Date'), ('time', 'Happens', 'Date'), ('time', 'Happens', 'May_2018'), ('time', 'Happens', 'discrete_steps')]\n",
      "12 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 15/25 [00:02<00:01,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 []\n",
      "14 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████▊                          | 17/25 [00:02<00:01,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 []\n",
      "16 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████████▎                   | 19/25 [00:02<00:00,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 []\n",
      "18 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 20/25 [00:02<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 22/25 [00:03<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 []\n",
      "21 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████▋   | 24/25 [00:03<00:00,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 []\n",
      "23 [('company', 'Supplies', 'components'), ('company', 'Supplies', 'product_varieties'), ('company', 'Supplies', 'commodity_item'), ('company', 'Supplies', 'supply_chain_strategies'), ('company', 'Supplies', 'high_quality_products'), ('company', 'Supplies', 'customer_orders'), ('company', 'Supplies', 'produce_in_China')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 []\n",
      "Sentence Embedding and Similarity search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:36<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [06:28<00:00, 15.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [01:40<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triple from answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████▋   | 24/25 [04:02<00:08,  8.02s/it]"
     ]
    }
   ],
   "source": [
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "for i in range(0,4):\n",
    "    chatbot_pipeline(questions, start_idx=i*25, end_idx=(i+1)*25, model=model, category=category, max_new_token=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1e6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-langchain]",
   "language": "python",
   "name": "conda-env-.conda-langchain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
