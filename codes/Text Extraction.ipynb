{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df421d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import pdfplumber\n",
    "import time\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f9cbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfplumber_jud_pdf(filename):\n",
    "    '''\n",
    "    Decide whether the pdf contains scanned pictures that can not be detected as texts directly\n",
    "    '''\n",
    "    doc = pdfplumber.open(filename)\n",
    "    for pages in doc.pages:\n",
    "        extraction = pages.extract_words()\n",
    "        # If the texts are not readable, return False\n",
    "        if not extraction:\n",
    "            return False\n",
    "        # Or if the texts can not be splitted by words, return False\n",
    "        words_lengths = [len(dictionary['text']) for dictionary in extraction]\n",
    "        if max(words_lengths) > 50:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def write_json(target_path, target_file, data):\n",
    "    '''\n",
    "    Output extracted results as a json file\n",
    "    '''\n",
    "    if not os.path.exists(target_path):\n",
    "        try:\n",
    "            os.makedirs(target_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            raise\n",
    "    file_path = target_path + '/' + target_file\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "def read_pdf_plum(file, file_path, target_path):\n",
    "    '''\n",
    "    Extract text directly if it is detectable\n",
    "    '''\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        page_num = 1\n",
    "        for page in pdf.pages:          \n",
    "            text = page.extract_text()\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "            page_str = str(page_num)\n",
    "            dictionary = {\n",
    "                'Article': file,\n",
    "                'Page': page_str,\n",
    "                'Text': text\n",
    "            }\n",
    "            target_file = file[:-4] + '_' + page_str + '.json'\n",
    "            write_json(target_path, target_file, dictionary)\n",
    "            page_num += 1\n",
    "\n",
    "\n",
    "def OCR_singlefile(file, file_path, target_path):\n",
    "    '''\n",
    "    Extract text from scanned pdfs using OCR\n",
    "    '''\n",
    "    image_file_list = []\n",
    "    # Part1 : Converting PDF to images\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        pdf_pages = convert_from_path(file_path, 500)\n",
    "        for page_enumeration, page in enumerate(pdf_pages, start=1):\n",
    "            filename = f\"{tempdir}\\page_{page_enumeration:03}.jpg\"\n",
    "            page.save(filename, \"JPEG\")\n",
    "            image_file_list.append(filename)\n",
    "\n",
    "    #Part2 - Recognizing text from the images using OCR\n",
    "    page_num = 1\n",
    "    for image_file in image_file_list:\n",
    "        text = str(((pytesseract.image_to_string(Image.open(image_file)))))\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        page_str = str(page_num)\n",
    "        dictionary = {\n",
    "                'Article': file,\n",
    "                'Page': page_str,\n",
    "                'Text': text\n",
    "            }\n",
    "        target_file = file[:-4] + '_' + page_str + '.json'\n",
    "        write_json(target_path, target_file, dictionary)\n",
    "        page_num += 1\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def text_extraction(in_path, target_path):\n",
    "    '''\n",
    "    Extract text from pdf files.\n",
    "    If the file contains scanned pictures, extract using OCR.\n",
    "    Otherwise, extract text directly.\n",
    "    Output a json file for every page\n",
    "    '''\n",
    "    for file in os.listdir(in_path): \n",
    "        if file.endswith(\".pdf\"):\n",
    "            start = time.time()\n",
    "            file_path = in_path + '/' + file\n",
    "            if pdfplumber_jud_pdf(file_path):\n",
    "                texts = read_pdf_plum(file, file_path, target_path)\n",
    "            else:\n",
    "                texts = OCR_singlefile(file, file_path, target_path)\n",
    "            end = time.time()\n",
    "            print(file + ': ' + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8f90520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2306.04819.pdf: 240.80949997901917\n",
      "2301.13174.pdf: 78.89621686935425\n",
      "Pictures.pdf: 11.98810601234436\n"
     ]
    }
   ],
   "source": [
    "in_path = '/Users/macbook/Desktop/DSI Capstone/Input PDFs'\n",
    "out_path = '/Users/macbook/Desktop/DSI Capstone/Input PDFs/Jsons'\n",
    "text_extraction(in_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37402b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
